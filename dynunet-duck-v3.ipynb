{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-02T17:05:20.472958Z","iopub.status.busy":"2024-07-02T17:05:20.472208Z","iopub.status.idle":"2024-07-02T17:05:22.375554Z","shell.execute_reply":"2024-07-02T17:05:22.374434Z","shell.execute_reply.started":"2024-07-02T17:05:20.472923Z"},"papermill":{"duration":2.538728,"end_time":"2024-07-01T07:50:28.637764","exception":false,"start_time":"2024-07-01T07:50:26.099036","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["get_ipython().system(f\"cd /kaggle/working/\")\n","GITHUB_TOKEN = \"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\"\n","USER = \"khanhdat111\"\n","branch = \"master\"\n","\n","CLONE_URL = f\"https://{USER}:{GITHUB_TOKEN}@github.com/{USER}/3D-DynUnet.git\"\n","get_ipython().system(f\"git clone -b {branch} {CLONE_URL}\")\n","%cd /kaggle/working/3D-DynUnet\n","\n","\n","import sys\n","sys.path.append(\"3D-DynUnet\")\n","\n","# import 3D-DynUnet\n","\n","%cd /kaggle/working/3D-DynUnet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:05:22.378379Z","iopub.status.busy":"2024-07-02T17:05:22.377998Z","iopub.status.idle":"2024-07-02T17:05:37.334254Z","shell.execute_reply":"2024-07-02T17:05:37.333128Z","shell.execute_reply.started":"2024-07-02T17:05:22.378338Z"},"papermill":{"duration":18.205592,"end_time":"2024-07-01T07:50:46.851426","exception":false,"start_time":"2024-07-01T07:50:28.645834","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!python /kaggle/working/3D-DynUnet/utils/setup.py e6bbb363de9b9e98994d5cd545f7ca585805c868"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:05:37.335914Z","iopub.status.busy":"2024-07-02T17:05:37.335606Z","iopub.status.idle":"2024-07-02T17:06:06.515366Z","shell.execute_reply":"2024-07-02T17:06:06.514183Z","shell.execute_reply.started":"2024-07-02T17:05:37.335885Z"},"papermill":{"duration":46.85484,"end_time":"2024-07-01T07:51:33.716088","exception":false,"start_time":"2024-07-01T07:50:46.861248","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!python /kaggle/working/3D-DynUnet/libs/data/prepare_datalist.py --path \"/kaggle/input/miccai-brats2018-original-dataset/MICCAI_BraTS_2018_Data_Training\" --output \"/kaggle/working/datalist.json\" --stage \"train\" --split 'true'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:06.519342Z","iopub.status.busy":"2024-07-02T17:06:06.518587Z","iopub.status.idle":"2024-07-02T17:06:35.552596Z","shell.execute_reply":"2024-07-02T17:06:35.551568Z","shell.execute_reply.started":"2024-07-02T17:06:06.519291Z"},"papermill":{"duration":28.364633,"end_time":"2024-07-01T07:52:02.090777","exception":false,"start_time":"2024-07-01T07:51:33.726144","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import json\n","from libs.data.dataset import dataloader\n","\n","with open(\"/kaggle/working/datalist.json\") as f:\n","    datalist = json.load(f)\n","    \n","train_loader, val_loader = dataloader(datalist, 1, 'train', True) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.554475Z","iopub.status.busy":"2024-07-02T17:06:35.553840Z","iopub.status.idle":"2024-07-02T17:06:35.558430Z","shell.execute_reply":"2024-07-02T17:06:35.557513Z","shell.execute_reply.started":"2024-07-02T17:06:35.554445Z"},"papermill":{"duration":0.017189,"end_time":"2024-07-01T07:52:02.117953","exception":false,"start_time":"2024-07-01T07:52:02.100764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ## Use to test pipeline\n","# datatest = {\"training\":datalist[\"training\"][:20],\"validation\": datalist[\"validation\"][:6]}    \n","# train_loader, val_loader = dataloader(datatest, 1, 'train', True)  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.559955Z","iopub.status.busy":"2024-07-02T17:06:35.559625Z","iopub.status.idle":"2024-07-02T17:06:35.570807Z","shell.execute_reply":"2024-07-02T17:06:35.569972Z","shell.execute_reply.started":"2024-07-02T17:06:35.559925Z"},"papermill":{"duration":0.019576,"end_time":"2024-07-01T07:52:02.147672","exception":false,"start_time":"2024-07-01T07:52:02.128096","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","from monai.networks.blocks.convolutions import Convolution\n","from monai.networks.layers.factories import Act, Norm\n","from monai.networks.layers.utils import get_act_layer, get_norm_layer\n","from collections.abc import Sequence\n","\n","from typing import List, Optional, Sequence, Tuple, Union\n","from torch.nn.functional import interpolate\n","from monai.networks.blocks.dynunet_block import UnetOutBlock, UnetBasicBlock, UnetResBlock"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.572196Z","iopub.status.busy":"2024-07-02T17:06:35.571928Z","iopub.status.idle":"2024-07-02T17:06:35.588645Z","shell.execute_reply":"2024-07-02T17:06:35.587719Z","shell.execute_reply.started":"2024-07-02T17:06:35.572174Z"},"papermill":{"duration":0.026777,"end_time":"2024-07-01T07:52:02.184052","exception":false,"start_time":"2024-07-01T07:52:02.157275","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_dilated_conv_layer(\n","    spatial_dims: int,\n","    in_channels: int,\n","    out_channels: int,\n","    kernel_size: Sequence[int] | int = 3,\n","    stride: Sequence[int] | int = 1,\n","    dilation: Sequence[int] | int = 1,  \n","    act: tuple | str | None = Act.PRELU,\n","    norm: tuple | str | None = Norm.INSTANCE,\n","    dropout: tuple | str | float | None = None,\n","    bias: bool = False,\n","    conv_only: bool = True,\n","    is_transposed: bool = False,\n","):\n","    padding = get_dilated_padding(kernel_size, stride, dilation) \n","    output_padding = None\n","    if is_transposed:\n","        output_padding = get_output_dilated_padding(kernel_size, stride, padding, dilation) \n","    return Convolution(\n","        spatial_dims,\n","        in_channels,\n","        out_channels,\n","        strides=stride,\n","        kernel_size=kernel_size,\n","        dilation=dilation,\n","        act=act,\n","        norm=norm,\n","        dropout=dropout,\n","        bias=bias,\n","        conv_only=conv_only,\n","        is_transposed=is_transposed,\n","        padding=padding,\n","        output_padding=output_padding,\n","    )\n","\n","def get_dilated_padding(kernel_size: Sequence[int] | int, stride: Sequence[int] | int, dilation: Sequence[int] | int) -> tuple[int, ...] | int:\n","    kernel_size_np = np.atleast_1d(kernel_size)\n","    stride_np = np.atleast_1d(stride)\n","    dilation_np = np.atleast_1d(dilation)\n","    padding_np = ((kernel_size_np - 1) * dilation_np + 1 - stride_np) / 2\n","    if np.min(padding_np) < 0:\n","        raise AssertionError(\"padding value should not be negative, please change the kernel size, stride, or dilation.\")\n","    padding = tuple(int(p) for p in padding_np)\n","    return padding if len(padding) > 1 else padding[0]\n","\n","def get_output_dilated_padding(\n","    kernel_size: Sequence[int] | int, stride: Sequence[int] | int, padding: Sequence[int] | int, dilation: Sequence[int] | int ) -> tuple[int, ...] | int:\n","    kernel_size_np = np.atleast_1d(kernel_size)\n","    stride_np = np.atleast_1d(stride)\n","    padding_np = np.atleast_1d(padding)\n","    dilation_np = np.atleast_1d(dilation)\n","    out_padding_np = 2 * padding_np + stride_np - (kernel_size_np - 1) * dilation_np - 1\n","    if np.min(out_padding_np) < 0:\n","        raise AssertionError(\"out_padding value should not be negative, please change the kernel size, stride, padding, or dilation.\")\n","    out_padding = tuple(int(p) for p in out_padding_np)\n","    return out_padding if len(out_padding) > 1 else out_padding[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.590074Z","iopub.status.busy":"2024-07-02T17:06:35.589780Z","iopub.status.idle":"2024-07-02T17:06:35.603300Z","shell.execute_reply":"2024-07-02T17:06:35.602382Z","shell.execute_reply.started":"2024-07-02T17:06:35.590051Z"},"papermill":{"duration":0.025103,"end_time":"2024-07-01T07:52:02.218906","exception":false,"start_time":"2024-07-01T07:52:02.193803","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_seperated_conv_layer(\n","    spatial_dims: int,\n","    in_channels: int,\n","    out_channels: int,\n","    kernel_size: Sequence[int] | int = 7,\n","    stride: Sequence[int] | int = 1,\n","    dilation: Sequence[int] | int = 1,  \n","    act: tuple | str | None = Act.PRELU,\n","    norm: tuple | str | None = Norm.INSTANCE,\n","    dropout: tuple | str | float | None = None,\n","    bias: bool = False,\n","    conv_only: bool = True,\n","    is_transposed: bool = False,\n","):\n","    padding = get_seperated_padding(kernel_size, stride, dilation) \n","    output_padding = None\n","    if is_transposed:\n","        output_padding = get_output_seperated_padding(kernel_size, stride, padding, dilation)  \n","    return Convolution(\n","        spatial_dims,\n","        in_channels,\n","        out_channels,\n","        strides=stride,\n","        kernel_size=kernel_size,\n","        dilation=dilation,\n","        act=act,\n","        norm=norm,\n","        dropout=dropout,\n","        bias=bias,\n","        conv_only=conv_only,\n","        is_transposed=is_transposed,\n","        padding=padding,\n","        output_padding=output_padding,\n","    )\n","\n","def get_seperated_padding(kernel_size: Sequence[int] | int, stride: Sequence[int] | int, dilation: Sequence[int] | int) -> tuple[int, ...] | int:\n","    kernel_size_np = np.atleast_1d(kernel_size)\n","    stride_np = np.atleast_1d(stride)\n","    dilation_np = np.atleast_1d(dilation)\n","    padding_np = ((kernel_size_np - 1) * dilation_np + 1 - stride_np) / 2\n","    if np.any(padding_np < 0):\n","        raise ValueError(\"Padding value should not be negative. Please adjust the kernel size, stride, or dilation.\")\n","    padding = tuple(int(p) for p in padding_np)\n","    return padding\n","\n","def get_output_seperated_padding(\n","    kernel_size: Sequence[int] | int, stride: Sequence[int] | int, padding: Sequence[int] | int, dilation: Sequence[int] | int ) -> tuple[int, ...] | int:\n","    kernel_size_np = np.atleast_1d(kernel_size)\n","    stride_np = np.atleast_1d(stride)\n","    padding_np = np.atleast_1d(padding)\n","    dilation_np = np.atleast_1d(dilation)\n","    out_padding_np = 2 * padding_np + stride_np - (kernel_size_np - 1) * dilation_np - 1\n","    if np.any(out_padding_np < 0):\n","        raise ValueError(\"Output padding value should not be negative. Please adjust the kernel size, stride, padding, or dilation.\")\n","    out_padding = tuple(int(p) for p in out_padding_np)\n","    return out_padding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.604702Z","iopub.status.busy":"2024-07-02T17:06:35.604410Z","iopub.status.idle":"2024-07-02T17:06:35.620088Z","shell.execute_reply":"2024-07-02T17:06:35.619301Z","shell.execute_reply.started":"2024-07-02T17:06:35.604676Z"},"papermill":{"duration":0.024622,"end_time":"2024-07-01T07:52:02.253375","exception":false,"start_time":"2024-07-01T07:52:02.228753","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_conv_layer(\n","    spatial_dims: int,\n","    in_channels: int,\n","    out_channels: int,\n","    kernel_size: Sequence[int] | int = 3,\n","    stride: Sequence[int] | int = 1,\n","    act: tuple | str | None = Act.PRELU,\n","    norm: tuple | str | None = Norm.INSTANCE,\n","    dropout: tuple | str | float | None = None,\n","    bias: bool = False,\n","    conv_only: bool = True,\n","    is_transposed: bool = False,\n","):\n","    padding = get_padding(kernel_size, stride)\n","    output_padding = None\n","    if is_transposed:\n","        output_padding = get_output_padding(kernel_size, stride, padding)\n","    return Convolution(\n","        spatial_dims,\n","        in_channels,\n","        out_channels,\n","        strides=stride,\n","        kernel_size=kernel_size,\n","        act=act,\n","        norm=norm,\n","        dropout=dropout,\n","        bias=bias,\n","        conv_only=conv_only,\n","        is_transposed=is_transposed,\n","        padding=padding,\n","        output_padding=output_padding,\n","    )\n","\n","\n","def get_padding(kernel_size: Sequence[int] | int, stride: Sequence[int] | int) -> tuple[int, ...] | int:\n","    kernel_size_np = np.atleast_1d(kernel_size)\n","    stride_np = np.atleast_1d(stride)\n","    padding_np = (kernel_size_np - stride_np + 1) / 2\n","    if np.min(padding_np) < 0:\n","        raise AssertionError(\"padding value should not be negative, please change the kernel size and/or stride.\")\n","    padding = tuple(int(p) for p in padding_np)\n","\n","    return padding if len(padding) > 1 else padding[0]\n","\n","\n","def get_output_padding(\n","    kernel_size: Sequence[int] | int, stride: Sequence[int] | int, padding: Sequence[int] | int\n",") -> tuple[int, ...] | int:\n","    kernel_size_np = np.atleast_1d(kernel_size)\n","    stride_np = np.atleast_1d(stride)\n","    padding_np = np.atleast_1d(padding)\n","\n","    out_padding_np = 2 * padding_np + stride_np - kernel_size_np\n","    if np.min(out_padding_np) < 0:\n","        raise AssertionError(\"out_padding value should not be negative, please change the kernel size and/or stride.\")\n","    out_padding = tuple(int(p) for p in out_padding_np)\n","\n","    return out_padding if len(out_padding) > 1 else out_padding[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.623108Z","iopub.status.busy":"2024-07-02T17:06:35.622857Z","iopub.status.idle":"2024-07-02T17:06:35.637458Z","shell.execute_reply":"2024-07-02T17:06:35.636681Z","shell.execute_reply.started":"2024-07-02T17:06:35.623088Z"},"papermill":{"duration":0.023614,"end_time":"2024-07-01T07:52:02.286801","exception":false,"start_time":"2024-07-01T07:52:02.263187","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class WideUnetBlock(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[int] | int,\n","        stride: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","    ):\n","        super().__init__()\n","        self.conv1 = get_dilated_conv_layer(\n","            spatial_dims,\n","            in_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            dilation= 1,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.conv2 = get_dilated_conv_layer(\n","            spatial_dims,\n","            out_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=1,\n","            dilation= 2,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.conv3 = get_dilated_conv_layer(\n","            spatial_dims,\n","            out_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=1,\n","            dilation= 3,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.lrelu = get_act_layer(name=act_name)\n","        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm3 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","\n","    def forward(self, inp):\n","        out = self.conv1(inp)\n","        out = self.norm1(out)\n","        out = self.lrelu(out)\n","        out = self.conv2(out)\n","        out = self.norm2(out)\n","        out = self.lrelu(out)\n","        out = self.conv3(out)\n","        out = self.norm3(out)\n","        out = self.lrelu(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.638809Z","iopub.status.busy":"2024-07-02T17:06:35.638478Z","iopub.status.idle":"2024-07-02T17:06:35.653185Z","shell.execute_reply":"2024-07-02T17:06:35.652284Z","shell.execute_reply.started":"2024-07-02T17:06:35.638780Z"},"papermill":{"duration":0.021926,"end_time":"2024-07-01T07:52:02.318304","exception":false,"start_time":"2024-07-01T07:52:02.296378","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class MidUnetBlock(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[int] | int,\n","        stride: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","    ):\n","        super().__init__()\n","        self.conv1 = get_dilated_conv_layer(\n","            spatial_dims,\n","            in_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            dilation= 1,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.conv2 = get_dilated_conv_layer(\n","            spatial_dims,\n","            out_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=1,\n","            dilation= 2,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.lrelu = get_act_layer(name=act_name)\n","        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","\n","    def forward(self, inp):\n","        out = self.conv1(inp)\n","        out = self.norm1(out)\n","        out = self.lrelu(out)\n","        out = self.conv2(out)\n","        out = self.norm2(out)\n","        out = self.lrelu(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.655166Z","iopub.status.busy":"2024-07-02T17:06:35.654442Z","iopub.status.idle":"2024-07-02T17:06:35.668755Z","shell.execute_reply":"2024-07-02T17:06:35.667840Z","shell.execute_reply.started":"2024-07-02T17:06:35.655142Z"},"papermill":{"duration":0.023849,"end_time":"2024-07-01T07:52:02.351822","exception":false,"start_time":"2024-07-01T07:52:02.327973","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class SeperatedUnetBlock(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: int,\n","        stride: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","    ):\n","        super().__init__()\n","        self.conv1 = get_seperated_conv_layer(\n","            spatial_dims,\n","            in_channels,\n","            out_channels,\n","            kernel_size=(1, 1, kernel_size),\n","            stride=1,\n","            dilation= 1,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.conv2 = get_seperated_conv_layer(\n","            spatial_dims,\n","            out_channels,\n","            out_channels,\n","            kernel_size=(1, kernel_size, 1),\n","            stride=1,\n","            dilation= 1,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.conv3 = get_seperated_conv_layer(\n","            spatial_dims,\n","            out_channels,\n","            out_channels,\n","            kernel_size=(kernel_size, 1, 1),\n","            stride=1,\n","            dilation= 1,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.lrelu = get_act_layer(name=act_name)\n","        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm3 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","\n","    def forward(self, inp):\n","        out = self.conv1(inp)\n","        out = self.norm1(out)\n","        out = self.lrelu(out)\n","        out = self.conv2(out)\n","        out = self.norm2(out)\n","        out = self.lrelu(out)\n","        out = self.conv3(out)\n","        out = self.norm3(out)\n","        out = self.lrelu(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.670157Z","iopub.status.busy":"2024-07-02T17:06:35.669882Z","iopub.status.idle":"2024-07-02T17:06:35.685634Z","shell.execute_reply":"2024-07-02T17:06:35.684685Z","shell.execute_reply.started":"2024-07-02T17:06:35.670135Z"},"papermill":{"duration":0.025803,"end_time":"2024-07-01T07:52:02.387232","exception":false,"start_time":"2024-07-01T07:52:02.361429","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class DuckBlock3D(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[int] | int,\n","        stride: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","    ):\n","        super(DuckBlock3D, self).__init__()\n","        \n","        self.wide_unet_block = WideUnetBlock(spatial_dims, in_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout)\n","        self.mid_unet_block = MidUnetBlock(spatial_dims, in_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout)\n","        self.separated_unet_block = SeperatedUnetBlock(spatial_dims, in_channels, out_channels, 5 , stride, norm_name, act_name, dropout)\n","        \n","        self.res_unet_block_1 = UnetResBlock(spatial_dims, in_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout)\n","        \n","        self.res_unet_block_2 = nn.Sequential(\n","            UnetResBlock(spatial_dims, in_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout),\n","            UnetResBlock(spatial_dims, out_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout)\n","        )\n","        \n","        self.res_unet_block_3 = nn.Sequential(\n","            UnetResBlock(spatial_dims, in_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout),\n","            UnetResBlock(spatial_dims, out_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout),\n","            UnetResBlock(spatial_dims, out_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout)\n","        )\n","        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","\n","    def forward(self, x):\n","        norm_1 = self.norm1(x)\n","        wide_out = self.wide_unet_block(norm_1)\n","        mid_out = self.mid_unet_block(norm_1)\n","        separated_out = self.separated_unet_block(norm_1)\n","        res_out_1 = self.res_unet_block_1(norm_1)\n","        res_out_2 = self.res_unet_block_2(norm_1)\n","        res_out_3 = self.res_unet_block_3(norm_1)\n","        out = mid_out  + separated_out + res_out_2 + res_out_1\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.687035Z","iopub.status.busy":"2024-07-02T17:06:35.686760Z","iopub.status.idle":"2024-07-02T17:06:35.700125Z","shell.execute_reply":"2024-07-02T17:06:35.699184Z","shell.execute_reply.started":"2024-07-02T17:06:35.687012Z"},"papermill":{"duration":0.019784,"end_time":"2024-07-01T07:52:02.416663","exception":false,"start_time":"2024-07-01T07:52:02.396879","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Residualx2_BottleNeck(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[int] | int,\n","        stride: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","    ):\n","        super(Residualx2_BottleNeck, self).__init__()\n","        \n","        self.res_unet_block_2 = nn.Sequential(\n","            UnetResBlock(spatial_dims, in_channels, out_channels, kernel_size, stride, norm_name, act_name, dropout),\n","            UnetResBlock(spatial_dims, out_channels, out_channels, kernel_size, 1, norm_name, act_name, dropout)\n","        )\n","\n","    def forward(self, x):\n","        out = self.res_unet_block_2(x)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.701614Z","iopub.status.busy":"2024-07-02T17:06:35.701300Z","iopub.status.idle":"2024-07-02T17:06:35.712542Z","shell.execute_reply":"2024-07-02T17:06:35.711763Z","shell.execute_reply.started":"2024-07-02T17:06:35.701590Z"},"papermill":{"duration":0.021788,"end_time":"2024-07-01T07:52:02.448197","exception":false,"start_time":"2024-07-01T07:52:02.426409","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class UnetBasicDuckBlock(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[int] | int,\n","        stride: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","    ):\n","        super().__init__()\n","        self.conv1 = get_conv_layer(\n","            spatial_dims,\n","            in_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            dropout=dropout,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","        )\n","        self.conv2 = DuckBlock3D(\n","            spatial_dims,\n","            out_channels,\n","            out_channels,\n","            kernel_size=kernel_size,\n","            stride=1,\n","            dropout=dropout,\n","            act_name=act_name,\n","            norm_name=norm_name\n","        )\n","        self.lrelu = get_act_layer(name=act_name)\n","        self.norm1 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","        self.norm2 = get_norm_layer(name=norm_name, spatial_dims=spatial_dims, channels=out_channels)\n","\n","    def forward(self, inp):\n","        out = self.conv1(inp)\n","        out = self.norm1(out)\n","        out = self.lrelu(out)\n","        out = self.conv2(out)\n","        out = self.norm2(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.713909Z","iopub.status.busy":"2024-07-02T17:06:35.713644Z","iopub.status.idle":"2024-07-02T17:06:35.726550Z","shell.execute_reply":"2024-07-02T17:06:35.725730Z","shell.execute_reply.started":"2024-07-02T17:06:35.713887Z"},"papermill":{"duration":0.02174,"end_time":"2024-07-01T07:52:02.479516","exception":false,"start_time":"2024-07-01T07:52:02.457776","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class UnetUpBlock(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[int] | int,\n","        stride: Sequence[int] | int,\n","        upsample_kernel_size: Sequence[int] | int,\n","        norm_name: tuple | str,\n","        act_name: tuple | str = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        dropout: tuple | str | float | None = None,\n","        trans_bias: bool = False,\n","    ):\n","        super().__init__()\n","        upsample_stride = upsample_kernel_size\n","        self.transp_conv = get_conv_layer(\n","            spatial_dims,\n","            in_channels,\n","            out_channels,\n","            kernel_size=upsample_kernel_size,\n","            stride=upsample_stride,\n","            dropout=dropout,\n","            bias=trans_bias,\n","            act=None,\n","            norm=None,\n","            conv_only=False,\n","            is_transposed=True,\n","        )\n","        self.conv_block = DuckBlock3D(\n","            spatial_dims,\n","            out_channels + out_channels,\n","            out_channels , \n","            kernel_size=kernel_size,\n","            stride=1,\n","            dropout=dropout,\n","            norm_name=norm_name,\n","            act_name=act_name,\n","        )\n","\n","    def forward(self, inp, skip):\n","        # number of channels for skip should equals to out_channels\n","        out = self.transp_conv(inp)\n","        out = torch.cat((out, skip), dim=1) # Sửa ở đây -----------------------------------\n","#         out = torch.add(out, skip)\n","        out = self.conv_block(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:35.728358Z","iopub.status.busy":"2024-07-02T17:06:35.727848Z","iopub.status.idle":"2024-07-02T17:06:36.148103Z","shell.execute_reply":"2024-07-02T17:06:36.147109Z","shell.execute_reply.started":"2024-07-02T17:06:35.728326Z"},"papermill":{"duration":0.059506,"end_time":"2024-07-01T07:52:02.549162","exception":false,"start_time":"2024-07-01T07:52:02.489656","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class DynUNetSkipLayer(nn.Module):\n","    heads: Optional[List[torch.Tensor]]\n","\n","    def __init__(self, index, downsample, upsample, next_layer, heads=None, super_head=None):\n","        super().__init__()\n","        self.downsample = downsample\n","        self.next_layer = next_layer\n","        self.upsample = upsample\n","        self.super_head = super_head\n","        self.heads = heads\n","        self.index = index\n","\n","    def forward(self, x):\n","        downout = self.downsample(x)\n","        nextout = self.next_layer(downout)\n","        upout = self.upsample(nextout, downout)\n","        if self.super_head is not None and self.heads is not None and self.index > 0:\n","            self.heads[self.index - 1] = self.super_head(upout)\n","\n","        return upout\n","\n","\n","class DynUNet_DUCK(nn.Module):\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Sequence[Union[Sequence[int], int]],\n","        strides: Sequence[Union[Sequence[int], int]],\n","        upsample_kernel_size: Sequence[Union[Sequence[int], int]],\n","        filters: Optional[Sequence[int]] = None,\n","        dropout: Optional[Union[Tuple, str, float]] = None,\n","        norm_name: Union[Tuple, str] = (\"INSTANCE\", {\"affine\": True}),\n","        act_name: Union[Tuple, str] = (\"leakyrelu\", {\"inplace\": True, \"negative_slope\": 0.01}),\n","        deep_supervision: bool = False,\n","        deep_supr_num: int = 1,\n","        res_block: bool = False,\n","        trans_bias: bool = False,\n","    ):\n","        super().__init__()\n","        self.spatial_dims = spatial_dims\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.strides = strides\n","        self.upsample_kernel_size = upsample_kernel_size\n","        self.norm_name = norm_name\n","        self.act_name = act_name\n","        self.dropout = dropout\n","        self.conv_block = UnetResBlock if res_block else DuckBlock3D\n","        self.conv_block_down = UnetBasicDuckBlock\n","        self.conv_block_bottle = UnetResBlock #Residualx2_BottleNeck\n","        self.trans_bias = trans_bias\n","        if filters is not None:\n","            self.filters = filters\n","            self.check_filters()\n","        else:\n","            self.filters = [min(2 ** (5 + i), 320 if spatial_dims == 3 else 512) for i in range(len(strides))]\n","        self.input_block = self.get_input_block()\n","        self.downsamples = self.get_downsamples()\n","        self.bottleneck = self.get_bottleneck()\n","        self.upsamples = self.get_upsamples()\n","        self.output_block = self.get_output_block(0)\n","        self.deep_supervision = deep_supervision\n","        self.deep_supr_num = deep_supr_num\n","        # initialize the typed list of supervision head outputs so that Torchscript can recognize what's going on\n","        self.heads: List[torch.Tensor] = [torch.rand(1)] * self.deep_supr_num\n","        if self.deep_supervision:\n","            self.deep_supervision_heads = self.get_deep_supervision_heads()\n","            self.check_deep_supr_num()\n","\n","        self.apply(self.initialize_weights)\n","        self.check_kernel_stride()\n","\n","        def create_skips(index, downsamples, upsamples, bottleneck, superheads=None):\n","            if len(downsamples) != len(upsamples):\n","                raise ValueError(f\"{len(downsamples)} != {len(upsamples)}\")\n","\n","            if len(downsamples) == 0:  # bottom of the network, pass the bottleneck block\n","                return bottleneck\n","\n","            if superheads is None:\n","                next_layer = create_skips(1 + index, downsamples[1:], upsamples[1:], bottleneck)\n","                return DynUNetSkipLayer(index, downsample=downsamples[0], upsample=upsamples[0], next_layer=next_layer)\n","\n","            super_head_flag = False\n","            if index == 0:  # don't associate a supervision head with self.input_block\n","                rest_heads = superheads\n","            else:\n","                if len(superheads) > 0:\n","                    super_head_flag = True\n","                    rest_heads = superheads[1:]\n","                else:\n","                    rest_heads = nn.ModuleList()\n","\n","            # create the next layer down, this will stop at the bottleneck layer\n","            next_layer = create_skips(1 + index, downsamples[1:], upsamples[1:], bottleneck, superheads=rest_heads)\n","            if super_head_flag:\n","                return DynUNetSkipLayer(\n","                    index,\n","                    downsample=downsamples[0],\n","                    upsample=upsamples[0],\n","                    next_layer=next_layer,\n","                    heads=self.heads,\n","                    super_head=superheads[0],\n","                )\n","\n","            return DynUNetSkipLayer(index, downsample=downsamples[0], upsample=upsamples[0], next_layer=next_layer)\n","\n","        if not self.deep_supervision:\n","            self.skip_layers = create_skips(\n","                0, [self.input_block] + list(self.downsamples), self.upsamples[::-1], self.bottleneck\n","            )\n","        else:\n","            self.skip_layers = create_skips(\n","                0,\n","                [self.input_block] + list(self.downsamples),\n","                self.upsamples[::-1],\n","                self.bottleneck,\n","                superheads=self.deep_supervision_heads,\n","            )\n","\n","    def check_kernel_stride(self):\n","        kernels, strides = self.kernel_size, self.strides\n","        error_msg = \"length of kernel_size and strides should be the same, and no less than 3.\"\n","        if len(kernels) != len(strides) or len(kernels) < 3:\n","            raise ValueError(error_msg)\n","\n","        for idx, k_i in enumerate(kernels):\n","            kernel, stride = k_i, strides[idx]\n","            if not isinstance(kernel, int):\n","                error_msg = f\"length of kernel_size in block {idx} should be the same as spatial_dims.\"\n","                if len(kernel) != self.spatial_dims:\n","                    raise ValueError(error_msg)\n","            if not isinstance(stride, int):\n","                error_msg = f\"length of stride in block {idx} should be the same as spatial_dims.\"\n","                if len(stride) != self.spatial_dims:\n","                    raise ValueError(error_msg)\n","\n","    def check_deep_supr_num(self):\n","        deep_supr_num, strides = self.deep_supr_num, self.strides\n","        num_up_layers = len(strides) - 1\n","        if deep_supr_num >= num_up_layers:\n","            raise ValueError(\"deep_supr_num should be less than the number of up sample layers.\")\n","        if deep_supr_num < 1:\n","            raise ValueError(\"deep_supr_num should be larger than 0.\")\n","\n","    def check_filters(self):\n","        filters = self.filters\n","        if len(filters) < len(self.strides):\n","            raise ValueError(\"length of filters should be no less than the length of strides.\")\n","        else:\n","            self.filters = filters[: len(self.strides)]\n","\n","    def forward(self, x):\n","        out = self.skip_layers(x)\n","        out = self.output_block(out)\n","        if self.training and self.deep_supervision:\n","            out_all = [out]\n","            for feature_map in self.heads:\n","                out_all.append(interpolate(feature_map, out.shape[2:]))\n","            return torch.stack(out_all, dim=1)\n","        return out\n","\n","    def get_input_block(self):\n","        return self.conv_block(\n","            self.spatial_dims,\n","            self.in_channels,\n","            self.filters[0],\n","            self.kernel_size[0],\n","            self.strides[0],\n","            self.norm_name,\n","            self.act_name,\n","            dropout=self.dropout,\n","        )\n","\n","    def get_bottleneck(self):\n","        return self.conv_block_bottle(\n","                self.spatial_dims,\n","                self.filters[-2],\n","                self.filters[-1],\n","                self.kernel_size[-1],\n","                self.strides[-1],\n","                self.norm_name,\n","                self.act_name,\n","                dropout=self.dropout,\n","            )\n","\n","    def get_output_block(self, idx: int):\n","        return UnetOutBlock(self.spatial_dims, self.filters[idx], self.out_channels, dropout=self.dropout)\n","\n","    def get_downsamples(self):\n","        inp, out = self.filters[:-2], self.filters[1:-1]\n","        strides, kernel_size = self.strides[1:-1], self.kernel_size[1:-1]\n","        return self.get_module_list(inp, out, kernel_size, strides, self.conv_block_down)  # type: ignore\n","\n","    def get_upsamples(self):\n","        inp, out = self.filters[1:][::-1], self.filters[:-1][::-1]\n","        strides, kernel_size = self.strides[1:][::-1], self.kernel_size[1:][::-1]\n","        upsample_kernel_size = self.upsample_kernel_size[::-1]\n","        return self.get_module_list(\n","            inp,  # type: ignore\n","            out,  # type: ignore\n","            kernel_size,\n","            strides,\n","            UnetUpBlock,  # type: ignore\n","            upsample_kernel_size,\n","            trans_bias=self.trans_bias,\n","        )\n","\n","    def get_module_list(\n","        self,\n","        in_channels: List[int],\n","        out_channels: List[int],\n","        kernel_size: Sequence[Union[Sequence[int], int]],\n","        strides: Sequence[Union[Sequence[int], int]],\n","        conv_block: nn.Module,\n","        upsample_kernel_size: Optional[Sequence[Union[Sequence[int], int]]] = None,\n","        trans_bias: bool = False,\n","    ):\n","        layers = []\n","        if upsample_kernel_size is not None:\n","            for in_c, out_c, kernel, stride, up_kernel in zip(\n","                in_channels, out_channels, kernel_size, strides, upsample_kernel_size\n","            ):\n","                params = {\n","                    \"spatial_dims\": self.spatial_dims,\n","                    \"in_channels\": in_c,\n","                    \"out_channels\": out_c,\n","                    \"kernel_size\": kernel,\n","                    \"stride\": stride,\n","                    \"norm_name\": self.norm_name,\n","                    \"act_name\": self.act_name,\n","                    \"dropout\": self.dropout,\n","                    \"upsample_kernel_size\": up_kernel,\n","                    \"trans_bias\": trans_bias,\n","                }\n","                layer = conv_block(**params)\n","                layers.append(layer)\n","        else:\n","            for in_c, out_c, kernel, stride in zip(in_channels, out_channels, kernel_size, strides):\n","                params = {\n","                    \"spatial_dims\": self.spatial_dims,\n","                    \"in_channels\": in_c,\n","                    \"out_channels\": out_c,\n","                    \"kernel_size\": kernel,\n","                    \"stride\": stride,\n","                    \"norm_name\": self.norm_name,\n","                    \"act_name\": self.act_name,\n","                    \"dropout\": self.dropout,\n","                }\n","                layer = conv_block(**params)\n","                layers.append(layer)\n","        return nn.ModuleList(layers)\n","\n","    def get_deep_supervision_heads(self):\n","        return nn.ModuleList([self.get_output_block(i + 1) for i in range(self.deep_supr_num)])\n","\n","    @staticmethod\n","    def initialize_weights(module):\n","        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n","            module.weight = nn.init.kaiming_normal_(module.weight, a=0.01)\n","            if module.bias is not None:\n","                module.bias = nn.init.constant_(module.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:36.149632Z","iopub.status.busy":"2024-07-02T17:06:36.149256Z","iopub.status.idle":"2024-07-02T17:06:37.596813Z","shell.execute_reply":"2024-07-02T17:06:37.595825Z","shell.execute_reply.started":"2024-07-02T17:06:36.149598Z"},"papermill":{"duration":1.116102,"end_time":"2024-07-01T07:52:03.675221","exception":false,"start_time":"2024-07-01T07:52:02.559119","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from torchsummary import summary\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = DynUNet_DUCK(\n","        spatial_dims=3,\n","        in_channels=4,\n","        out_channels=3,\n","        filters = [17, 34, 68, 136, 272, 272],\n","        kernel_size= [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],\n","        strides= [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n","        upsample_kernel_size=[[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n","        norm_name=\"INSTANCE\",\n","        act_name=\"leakyrelu\",\n","        deep_supervision=False,\n","        deep_supr_num=1,).to(device)\n","\n","# summary(model, input_size=(1, 4, 128, 128, 128))\n","print(model)\n","\n","\n","# # Tạo input mẫu\n","# input_tensor = torch.randn(1, 4, 128, 128, 128).to(device)\n","# output = model(input_tensor)\n","# print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-02T17:06:59.690256Z","iopub.status.busy":"2024-07-02T17:06:59.689359Z","iopub.status.idle":"2024-07-02T17:10:04.285046Z","shell.execute_reply":"2024-07-02T17:10:04.282875Z","shell.execute_reply.started":"2024-07-02T17:06:59.690224Z"},"papermill":{"duration":41548.161884,"end_time":"2024-07-01T19:24:35.746449","exception":false,"start_time":"2024-07-01T07:52:07.584565","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import torch\n","\n","from monai.data import DataLoader, decollate_batch\n","from monai.losses import DiceLoss\n","from monai.inferers import sliding_window_inference\n","from monai.metrics import DiceMetric\n","from monai.transforms import Compose, Activations, AsDiscrete\n","import wandb\n","\n","from seg_train import run\n","\n","config = {\n","    \"max_epochs\": 10,\n","    \"name\":\"DynUnet_DUCK_v4\",\n","    \"lr\":3e-4,\n","    \"results_dir\":\"/kaggle/working/results\",\n","    \"project\":\"Duck_BraTS18_v4\",\n","    \"step_val\": 5\n","}\n","        \n","optimizer = torch.optim.Adam(model.parameters(), 3e-4, weight_decay=1e-4)\n","\n","loss_function = DiceLoss(smooth_nr=0, smooth_dr=5e-1, squared_pred=True, to_onehot_y=False, sigmoid=True)\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n","\n","dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n","dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n","\n","logger = None\n","logger = wandb.init(project=config['project'], name = config['name'], config=config, dir=\"/kaggle/input/pretrain/BrainTumour_Seg/\", resume=True)\n","\n","run(model, train_loader, val_loader, optimizer, loss_function, lr_scheduler, dice_metric, dice_metric_batch, logger, config, sepoch=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":5.631248,"end_time":"2024-07-01T19:24:41.457125","exception":true,"start_time":"2024-07-01T19:24:35.825877","status":"failed"},"tags":[],"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torch.nn as nn\n","\n","model.eval()\n","\n","for i in range(2):\n","    data = next(iter(train_loader))\n","    y_hat = model(data['image'].to('cuda'))\n","    for label, pred in zip(data['label'][0], y_hat[0]):\n","        plt.subplot(1,2,1)\n","        plt.imshow(label[:,:,70].cpu().detach().numpy()) \n","        plt.subplot(1,2,2)\n","        plt.imshow((nn.Sigmoid()(pred[:,:,70]).cpu().detach().numpy()))\n","        plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2319227,"sourceId":3904475,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":41661.067782,"end_time":"2024-07-01T19:24:44.352101","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-01T07:50:23.284319","version":"2.5.0"}},"nbformat":4,"nbformat_minor":4}
